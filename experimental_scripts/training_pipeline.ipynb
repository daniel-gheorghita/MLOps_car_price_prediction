{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d54a0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from time import sleep, time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from evidently.report import Report\n",
    "from evidently import ColumnMapping\n",
    "from evidently.metrics import ColumnDriftMetric, DatasetDriftMetric, DatasetMissingValuesMetric\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "import mlflow.sklearn\n",
    "from pprint import pprint\n",
    "from prefect import flow, task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb54621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAILABLE_DATA_PATH = './data/available'\n",
    "MODEL_NAME = 'car-price-predictor'\n",
    "DEBUG = True\n",
    "if DEBUG:\n",
    "    !rm ./data/available/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3cdf40b-c0e0-4b85-8ea4-c7a70b4c963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the MLFlow tracking server\n",
    "mlflow.set_tracking_uri(\"http://0.0.0.0:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07499640",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/prefect/tasks.py:326: UserWarning: A task named 'load_existing_dataset' and defined at '/tmp/ipykernel_3489/3025492780.py:1' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/prefect/tasks.py:326: UserWarning: A task named 'train_model' and defined at '/tmp/ipykernel_3489/3025492780.py:13' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/prefect/tasks.py:326: UserWarning: A task named 'evaluate_model' and defined at '/tmp/ipykernel_3489/3025492780.py:60' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/prefect/tasks.py:326: UserWarning: A task named 'compare_datasets' and defined at '/tmp/ipykernel_3489/3025492780.py:75' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/prefect/tasks.py:326: UserWarning: A task named 'calculate_monitoring_metrics' and defined at '/tmp/ipykernel_3489/3025492780.py:92' conflicts with another task. Consider specifying a unique `name` parameter in the task definition:\n",
      "\n",
      " `@task(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/site-packages/prefect/flows.py:273: UserWarning: A flow named 'main-training-flow' and defined at '/tmp/ipykernel_3489/3025492780.py:135' conflicts with another flow. Consider specifying a unique `name` parameter in the flow definition:\n",
      "\n",
      " `@flow(name='my_unique_name', ...)`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@task()\n",
    "def load_existing_dataset(input_folder):\n",
    "    assert os.path.exists(input_folder), f\"Input location {input_folder} does not exist.\"\n",
    "    files_list = glob.glob(os.path.join(input_folder, \"*.csv\"))\n",
    "    print(f\"Found {len(files_list)} data files.\")\n",
    "    if len(files_list) == 0:\n",
    "        print(\"No data available.\")\n",
    "        return None\n",
    "    df = pd.concat(map(pd.read_csv, files_list))\n",
    "    print(\"Loaded available data.\")\n",
    "    return df\n",
    "\n",
    "@task()\n",
    "def train_model(df, feature_columns, target_column, model_type = 'LinearRegressor'):\n",
    "\n",
    "    df=df.dropna().reset_index(drop=True)\n",
    "    X = df[feature_columns].values\n",
    "    #print(np.shape(X))\n",
    "    y = df[target_column].values\n",
    "    #print(np.shape(y))\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(\"model_type\", model_type)\n",
    "        mlflow.log_param(\"latest_data_year\", df['year'].max())\n",
    "        mlflow.log_param(\"feature_columns\", feature_columns)\n",
    "        mlflow.log_param(\"target_column\", target_column)\n",
    "\n",
    "        if model_type == \"LinearRegressor\":\n",
    "            model = LinearRegression().fit(X, y)\n",
    "        elif model_type == \"GradientBoostingRegressor\":\n",
    "            model = GradientBoostingRegressor().fit(X, y)\n",
    "        elif model_type == \"RandomForestRegressor\":\n",
    "            model = RandomForestRegressor().fit(X, y)\n",
    "\n",
    "        y_pred = model.predict(X)\n",
    "        rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "        score = model.score(X,y)\n",
    "\n",
    "        mlflow.log_metric(\"train_rmse\", rmse)\n",
    "        mlflow.log_metric(\"train_score\", score)\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    \n",
    "    #\n",
    "    #model = GradientBoostingRegressor().fit(X, y)\n",
    "\n",
    "    #print(\"Model score on training data:\", model.score(X, y))\n",
    "    return model\n",
    "    #print(model.coef_)\n",
    "    #print(model.intercept_)\n",
    "    '''\n",
    "    print(model.predict(df[df['year']<85][feature_cols].values))\n",
    "    plt.plot(model.predict(df[df['year']<85][feature_cols].values),label='Predicted', alpha=0.5)\n",
    "    plt.plot(df[df['year']<85][target_col].values,label='Measured', alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "\n",
    "@task()\n",
    "def evaluate_model(model, df_test, feature_columns, target_column, display=True):\n",
    "    df_test=df_test.dropna().reset_index(drop=True)\n",
    "    X = df_test[feature_columns].values\n",
    "    y = df_test[target_column].values\n",
    "    print(\"Model score :\", model.score(X, y))\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "    print(\"Model rmse: \", rmse)\n",
    "    if display:\n",
    "        plt.plot(model.predict(df_test[feature_columns].values),label='Predicted', alpha=0.5)\n",
    "        plt.plot(df_test[target_column].values,label='Measured', alpha=0.5)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "@task()\n",
    "def compare_datasets(df, latest_training_data, feature_columns, target_column, display=True):\n",
    "    #print(df[feature_columns + [target_column]].mean())\n",
    "    #print(df_new[feature_columns + [target_column]].mean())\n",
    "    reference_data = df[df['year'] <= latest_training_data]\n",
    "    current_data = df[df['year'] > latest_training_data]\n",
    "    \n",
    "    reference_data_mean_values = np.array(reference_data[feature_columns + [target_column]].mean().values)\n",
    "    current_data_new_mean_values = np.array(current_data[feature_columns + [target_column]].mean().values)\n",
    "    if display:\n",
    "        plt.plot(current_data_new_mean_values / reference_data_mean_values * 100, label='new/available data [%]')\n",
    "        plt.xticks(list(range(len(reference_data_mean_values))), \n",
    "                   reference_data[feature_columns + [target_column]].mean().index, \n",
    "                   rotation=45)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "@task()\n",
    "def calculate_monitoring_metrics(model, df, latest_training_data, \n",
    "                                 numerical_features = None, \n",
    "                                 categorical_features = None, \n",
    "                                 target_column = None):\n",
    "    print(latest_training_data)\n",
    "    print(df['year'].min(), df['year'].max())\n",
    "    all_features_list = []\n",
    "    if numerical_features:\n",
    "        all_features_list = all_features_list + numerical_features\n",
    "    if categorical_features:\n",
    "        all_features = all_features_list + categorical_features\n",
    "        \n",
    "    column_mapping = ColumnMapping(\n",
    "        prediction='prediction',\n",
    "        numerical_features=numerical_features,\n",
    "        categorical_features=categorical_features,\n",
    "        target=target_column\n",
    "    )\n",
    "    report = Report(metrics = [\n",
    "        ColumnDriftMetric(column_name='prediction'),\n",
    "        DatasetDriftMetric(),\n",
    "        DatasetMissingValuesMetric()\n",
    "    ])\n",
    "    \n",
    "    reference_data = df[df['year'] <= latest_training_data]\n",
    "    current_data = df[df['year'] > latest_training_data]\n",
    "    current_data['prediction'] = model.predict(current_data[all_features_list].fillna(0))\n",
    "    reference_data['prediction'] = model.predict(reference_data[all_features_list].fillna(0))\n",
    "\n",
    "    report.run(reference_data = reference_data, current_data = current_data, column_mapping=column_mapping)\n",
    "\n",
    "    result = report.as_dict()\n",
    "\n",
    "    prediction_drift = result['metrics'][0]['result']['drift_score']\n",
    "    num_drifted_columns = result['metrics'][1]['result']['number_of_drifted_columns']\n",
    "    share_missing_values = result['metrics'][2]['result']['current']['share_of_missing_values']\n",
    "    \n",
    "    print(\"prediction_drift:\", prediction_drift)\n",
    "    print(\"num_drifted_columns:\", num_drifted_columns)\n",
    "    print(\"share_missing_values:\", share_missing_values)\n",
    "\n",
    "\n",
    "@flow()\n",
    "def main_training_flow(available_data_path, model_name, display=True):\n",
    "    feature_cols = ['horsepower','places', 'doors','speed', 'consumption', 'acceleration']\n",
    "    #feature_cols = ['horsepower']\n",
    "    target_col = 'price_eur'\n",
    "    latest_training_data = 1900\n",
    "    latest_available_data = 1900\n",
    "    model = None\n",
    "    client = MlflowClient()\n",
    "    if DEBUG: \n",
    "        # Delete a registered model along with all its versions\n",
    "        try:\n",
    "            client.delete_registered_model(name=model_name)\n",
    "        except:\n",
    "            print(f\"Model {MODEL_NAME} not present in the registry.\")\n",
    "\n",
    "    model = None\n",
    "    print(\"----- Iteration -----\")\n",
    "\n",
    "    # Load data\n",
    "    df = load_existing_dataset(available_data_path)\n",
    "    if df is None:\n",
    "        print(\"No available data for training.\")\n",
    "        return\n",
    "    latest_available_data = df['year'].max()\n",
    "        \n",
    "    if df is not None and latest_training_data < df['year'].max() and latest_training_data > df['year'].min():\n",
    "        #print(latest_training_data, df['year'].max() , df['year'].min())\n",
    "        compare_datasets(df, latest_training_data, feature_cols, target_col, display=display)\n",
    "        \n",
    "    # Monitoring\n",
    "    if model is not None and df is not None:\n",
    "        calculate_monitoring_metrics(model, df.copy(), latest_training_data, numerical_features = feature_cols)\n",
    "\n",
    "    # Get the latest model version from the registry\n",
    "    for rm in client.search_registered_models():\n",
    "        if rm.latest_versions[0].run_id.name != model_name:\n",
    "            continue\n",
    "        run_id = rm.latest_versions[0].run_id\n",
    "        run_obj = mlflow.get_run(run_id)\n",
    "        run_metrics = run_obj.data.metrics\n",
    "        run_params = run_obj.data.params\n",
    "        latest_training_data = int(run_params['latest_data_year'])\n",
    "        print(run_params)\n",
    "        \n",
    "        # Load the model\n",
    "        model_uri = \"runs:/{}/model\".format(run_id)\n",
    "        try:\n",
    "            model = mlflow.sklearn.load_model(model_uri)\n",
    "        except:\n",
    "            print(\"No model found.\")\n",
    "    '''\n",
    "    model_version = \"latest\"\n",
    "    try:\n",
    "        model = mlflow.sklearn.load_model(model_uri=f\"models:/{model_name}/{model_version}\")\n",
    "    except:\n",
    "        print(f\"Model {model_name}:{model_version} was not found.\")\n",
    "    '''\n",
    "    #if df is not None:\n",
    "    #    model = train_model(df, feature_columns=feature_cols, target_column=target_col)\n",
    "    #    latest_training_data = df['year'].max()\n",
    "        \n",
    "    if model is not None:\n",
    "        evaluate_model(model, df, feature_columns=feature_cols, target_column=target_col, display=display)\n",
    "        \n",
    "    # (Re)train model\n",
    "    EXPERIMENT_NAME = f\"car-price-{int(time())}\"\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "    for model_type in [\"LinearRegressor\", \"GradientBoostingRegressor\", \"RandomForestRegressor\"]:\n",
    "        model = train_model(df, feature_columns=feature_cols, target_column=target_col, model_type = model_type)\n",
    "        evaluate_model(model, df, feature_columns=feature_cols, target_column=target_col, display=display)\n",
    "\n",
    "    # Select the model with the lowest test RMSE\n",
    "    experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    best_run = client.search_runs(\n",
    "            experiment_ids=experiment.experiment_id,\n",
    "            filter_string=\"\",\n",
    "            run_view_type=ViewType.ACTIVE_ONLY,\n",
    "            max_results=1,\n",
    "            order_by=[\"metrics.test_rmse ASC\"],\n",
    "        )[0]\n",
    "    #print(best_run)\n",
    "    \n",
    "    # Register the best model\n",
    "    \n",
    "    result = mlflow.register_model(\n",
    "        f\"runs:/{best_run.info.run_id}/model\", model_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "242cbc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:55:41.607 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | prefect.engine - Created flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'gray-pegasus'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'main-training-flow'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:55:41.607 | \u001b[36mINFO\u001b[0m    | prefect.engine - Created flow run\u001b[35m 'gray-pegasus'\u001b[0m for flow\u001b[1;35m 'main-training-flow'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model car-price-predictor not present in the registry.\n",
      "----- Iteration -----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:55:42.090 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'gray-pegasus'</span> - Created task run 'load_existing_dataset-0' for task 'load_existing_dataset'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:55:42.090 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'gray-pegasus'\u001b[0m - Created task run 'load_existing_dataset-0' for task 'load_existing_dataset'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:55:42.102 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'gray-pegasus'</span> - Executing 'load_existing_dataset-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:55:42.102 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'gray-pegasus'\u001b[0m - Executing 'load_existing_dataset-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 data files.\n",
      "Loaded available data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:55:42.438 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_existing_dataset-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:55:42.438 | \u001b[36mINFO\u001b[0m    | Task run 'load_existing_dataset-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/08/02 17:55:42 INFO mlflow.tracking.fluent: Experiment with name 'car-price-1690998942' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:55:43.053 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'gray-pegasus'</span> - Created task run 'train_model-0' for task 'train_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:55:43.053 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'gray-pegasus'\u001b[0m - Created task run 'train_model-0' for task 'train_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:55:43.058 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'gray-pegasus'</span> - Executing 'train_model-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:55:43.058 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'gray-pegasus'\u001b[0m - Executing 'train_model-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/08/02 17:55:43 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:56:05.050 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'train_model-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:56:05.050 | \u001b[36mINFO\u001b[0m    | Task run 'train_model-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:56:05.601 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'gray-pegasus'</span> - Created task run 'evaluate_model-0' for task 'evaluate_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:56:05.601 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'gray-pegasus'\u001b[0m - Created task run 'evaluate_model-0' for task 'evaluate_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:56:05.617 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'gray-pegasus'</span> - Executing 'evaluate_model-0' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:56:05.617 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'gray-pegasus'\u001b[0m - Executing 'evaluate_model-0' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score : 0.7866553199819124\n",
      "Model rmse:  426.4561056591503\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:56:06.892 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'evaluate_model-0' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:56:06.892 | \u001b[36mINFO\u001b[0m    | Task run 'evaluate_model-0' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:56:06.996 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'gray-pegasus'</span> - Created task run 'train_model-1' for task 'train_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:56:06.996 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'gray-pegasus'\u001b[0m - Created task run 'train_model-1' for task 'train_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:56:07.001 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'gray-pegasus'</span> - Executing 'train_model-1' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:56:07.001 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'gray-pegasus'\u001b[0m - Executing 'train_model-1' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:56:15.443 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'train_model-1' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:56:15.443 | \u001b[36mINFO\u001b[0m    | Task run 'train_model-1' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:56:15.542 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'gray-pegasus'</span> - Created task run 'evaluate_model-1' for task 'evaluate_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:56:15.542 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'gray-pegasus'\u001b[0m - Created task run 'evaluate_model-1' for task 'evaluate_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:56:15.546 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'gray-pegasus'</span> - Executing 'evaluate_model-1' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:56:15.546 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'gray-pegasus'\u001b[0m - Executing 'evaluate_model-1' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score : 0.9505163840908024\n",
      "Model rmse:  205.38283362674244\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:56:15.857 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'evaluate_model-1' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:56:15.857 | \u001b[36mINFO\u001b[0m    | Task run 'evaluate_model-1' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:56:15.957 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'gray-pegasus'</span> - Created task run 'train_model-2' for task 'train_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:56:15.957 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'gray-pegasus'\u001b[0m - Created task run 'train_model-2' for task 'train_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:56:15.961 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'gray-pegasus'</span> - Executing 'train_model-2' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:56:15.961 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'gray-pegasus'\u001b[0m - Executing 'train_model-2' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:56:21.080 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'train_model-2' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:56:21.080 | \u001b[36mINFO\u001b[0m    | Task run 'train_model-2' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:56:21.197 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'gray-pegasus'</span> - Created task run 'evaluate_model-2' for task 'evaluate_model'\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:56:21.197 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'gray-pegasus'\u001b[0m - Created task run 'evaluate_model-2' for task 'evaluate_model'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:56:21.201 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'gray-pegasus'</span> - Executing 'evaluate_model-2' immediately...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:56:21.201 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'gray-pegasus'\u001b[0m - Executing 'evaluate_model-2' immediately...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score : 0.9442498085618035\n",
      "Model rmse:  218.00005808750328\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:56:21.510 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'evaluate_model-2' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:56:21.510 | \u001b[36mINFO\u001b[0m    | Task run 'evaluate_model-2' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'car-price-predictor'.\n",
      "2023/08/02 17:56:22 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: car-price-predictor, version 1\n",
      "Created version '1' of model 'car-price-predictor'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:56:22.265 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'gray-pegasus'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>('All states completed.')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:56:22.265 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'gray-pegasus'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m('All states completed.')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `DataFrame`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `LinearRegression`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `NoneType`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `GradientBoostingRegressor`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `NoneType`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `RandomForestRegressor`')),\n",
       " Completed(message=None, type=COMPLETED, result=UnpersistedResult(type='unpersisted', artifact_type='result', artifact_description='Unpersisted result of type `NoneType`'))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_training_flow(available_data_path = AVAILABLE_DATA_PATH, model_name=MODEL_NAME, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832fef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test service "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
